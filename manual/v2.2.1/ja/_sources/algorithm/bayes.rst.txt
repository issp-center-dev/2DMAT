ベイズ最適化 ``bayes``
*******************************

.. _PHYSBO: https://pasums.issp.u-tokyo.ac.jp/physbo

``bayes`` はベイズ最適化を用いてパラメータ探索を行う ``Algorithm`` です。

実装には `PHYSBO`_ を用いています。

前準備
~~~~~~
あらかじめ `PHYSBO`_ をインストールしておく必要があります。::

  python3 -m pip install physbo

`mpi4py <https://mpi4py.readthedocs.io/en/stable/>`_ がインストールされている場合、
MPI 並列計算が可能です。

入力パラメータ
~~~~~~~~~~~~~~~~~~~~~

[``algorithmparam``] セクション
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

探索パラメータ空間を定義します。

``mesh_path`` が定義されている場合はメッシュファイルから読み込みます。
メッシュファイルは1行がパラメータ空間中の1点を意味しており、
1列目がデータ番号で、2列目以降が各次元の座標です。

``mesh_path`` が定義されていない場合は、 ``min_list``, ``max_list``, ``num_list`` を用いて、
各パラメータについて等間隔なグリッドを作成します。

- ``mesh_path``

  形式: string型

  説明: メッシュデータの情報が記載された参照用ファイルへのパス。

- ``min_list``

  形式: 実数型のリスト。長さはdimensionの値と一致させます。

  説明: パラメータが取りうる最小値。

- ``max_list``

  形式: 実数型のリスト。長さはdimensionの値と一致させます。

  説明: パラメータが取りうる最大値。

- ``num_list``

  形式: 整数型のリスト。長さはdimensionの値と一致させます。

  説明: パラメータが取りうる数。

[``algorithm.bayes``] セクション
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

手法のハイパーパラメータを定義します。

- ``random_max_num_probes``

  形式： int型 (default: 20)

  説明: ベイズ最適化を行う前に行うランダムサンプリングの回数(パラメータとスコアが初めに無い場合にはランダムサンプリングは必須)。

- ``bayes_max_num_probes``

  形式： int型 (default: 40)

  説明: ベイズ最適化を行う回数。

- ``score``

  形式: string型 (default: ``TS`` )

  説明: スコア関数を指定するパラメータ。
  ``EI``, ``PI``, ``TS`` より選択可能で、それぞれ "expected improvement", "probability of improvement", "Thompson sampling" を行う。

- ``interval``

  形式： int型 (default: 5)

  説明: 指定したインターバルごとに、ハイパーパラメータを学習します。負の値を指定すると、ハイパーパラメータの学習は行われません。
  0を指定すると、ハイパーパラメータの学習は最初のステップでのみ行われます。

- ``num_rand_basis``

  形式： int型 (default: 5000)

  説明： 基底関数の数。0を指定した場合、Bayesian linear modelを利用しない通常のガウシアンプロセスが行われます。


アルゴリズム補助ファイル
~~~~~~~~~~~~~~~~~~~~~~~~~~

メッシュ定義ファイル
^^^^^^^^^^^^^^^^^^^^^^^^^^

本ファイルで探索するグリッド空間を定義します。
1列目にメッシュのインデックス、
2列目以降は ``[solver.param]`` セクションにある、
``string_list`` で定義された変数に入る値が入ります。

以下、サンプルを記載します。

.. code-block::

    1 6.000000 6.000000
    2 6.000000 5.750000
    3 6.000000 5.500000
    4 6.000000 5.250000
    5 6.000000 5.000000
    6 6.000000 4.750000
    7 6.000000 4.500000
    8 6.000000 4.250000
    9 6.000000 4.000000
    ...

出力ファイル
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

``BayesData.txt`` 
^^^^^^^^^^^^^^^^^^^^^^
最適化過程の各ステップにおいて、
パラメータと対応する目的関数の値が、
これまでの最適パラメータとそのステップで探索したパラメータの順に記載されます。

.. code-block::

    #step z1 z2 R-factor z1_action z2_action R-factor_action
    0 4.75 4.5 0.05141906746102885 4.75 4.5 0.05141906746102885
    1 4.75 4.5 0.05141906746102885 6.0 4.75 0.06591878368102033
    2 5.5 4.25 0.04380131351780189 5.5 4.25 0.04380131351780189
    3 5.0 4.25 0.02312528177606794 5.0 4.25 0.02312528177606794
    ...


アルゴリズム解説
~~~~~~~~~~~~~~~~~~~~~~

`ベイズ最適化 (Bayesian optimization, BO) <https://en.wikipedia.org/wiki/Bayesian_optimization>`_ は、機械学習を援用した最適化アルゴリズムであり、特に目的関数の評価に時間がかかるときに強力な手法です。

BO では目的関数 :math:`f(\vec{x})` を、評価が早く最適化のしやすいモデル関数（多くの場合ガウス過程） :math:`g(\vec{x})` で近似します。
:math:`g` は、あらかじめ適当に決められたいくつかの点（訓練データセット） :math:`\{\vec{x}_i\}_{i=1}^N` での目的関数の値 :math:`\{f(\vec{x}_i)\}_{i=1}^N` をよく再現するように訓練されます。
パラメータ空間の各点において、訓練された :math:`g(\vec{x})` の値の期待値およびその誤差から求められる「スコア」 (acquition function) が最適になるような点 :math:`\vec{x}_{N+1}` を次の計算候補点として提案します。
:math:`f(\vec{x}_{N+1})` を評価し、 訓練データセットに追加、 :math:`g` を再訓練します。
こうした探索を適当な回数繰り返した後、目的関数の値が最も良かったものを最適解として返します。

少ない誤差でより良い期待値を与える点は、正解である可能性こそ高いですが、すでに十分な情報があると考えられるので、モデル関数の精度向上にはあまり寄与しません。
逆に、誤差の大きな点は正解ではないかもしれませんが、情報の少ない場所であり、モデル関数の更新には有益だと考えられます。
前者を選ぶことを「活用」、後者を選ぶことを「探索」とよび、両者をバランス良く行うのが重要です。
「スコア」の定義はこれらをどう選ぶかを定めます。

2DMAT では、ベイズ最適化のライブラリとして、 `PHYSBO`_ を用います。
PHYSBO は ``mapper_mpi`` のように、あらかじめ決めておいた候補点の集合に対して「スコア」を計算して、最適解を提案します。
候補点の集合を分割することでMPI 並列実行が可能です。
また、 訓練データの点数 :math:`N` に対して線形の計算量でモデル関数の評価、ひいては「スコア」の計算が可能となるようなカーネルを用いています。
PHYSBO では「スコア」関数として "expected improvement (EI)", "probability of improvement (PI)", "Thompson sampling (TS)" が利用できます。
